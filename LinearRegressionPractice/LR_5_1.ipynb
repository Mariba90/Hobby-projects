{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using Turi Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:55:20.167375Z",
     "start_time": "2022-02-11T03:55:19.344128Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log, sqrt\n",
    "from sklearn import linear_model  # using scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:03:11.867542Z",
     "start_time": "2022-02-11T04:03:11.649615Z"
    }
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in Turi Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:56:04.197736Z",
     "start_time": "2022-02-11T03:56:04.098861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, normalize=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    "\n",
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "**QUIZ QUESTION According to this list of weights, which of the features have been chosen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T03:58:37.977673Z",
     "start_time": "2022-02-11T03:58:37.965134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bedrooms': 0.0,\n",
       " 'bedrooms_square': 0.0,\n",
       " 'bathrooms': 0.0,\n",
       " 'sqft_living': 134.43931395541435,\n",
       " 'sqft_living_sqrt': 0.0,\n",
       " 'sqft_lot': 0.0,\n",
       " 'sqft_lot_sqrt': 0.0,\n",
       " 'floors': 0.0,\n",
       " 'floors_square': 0.0,\n",
       " 'waterfront': 0.0,\n",
       " 'view': 24750.00458560947,\n",
       " 'condition': 0.0,\n",
       " 'grade': 61749.10309070815,\n",
       " 'sqft_above': 0.0,\n",
       " 'sqft_basement': 0.0,\n",
       " 'yr_built': -0.0,\n",
       " 'yr_renovated': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features_dic = dict()\n",
    "for i,feature in enumerate(all_features):\n",
    "    lasso_features_dic[feature]=model_all.coef_[i]\n",
    "lasso_features_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:02:12.370855Z",
     "start_time": "2022-02-11T04:02:12.350850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 500.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 1000,\n",
       " 'normalize': True,\n",
       " 'positive': False,\n",
       " 'precompute': False,\n",
       " 'random_state': None,\n",
       " 'selection': 'cyclic',\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.get_params(['deep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:50:14.975437Z",
     "start_time": "2022-02-13T22:50:14.959685Z"
    }
   },
   "outputs": [],
   "source": [
    "def sci(value):\n",
    "    return('{:.5e}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectin L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!\n",
    "\n",
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:03:27.776186Z",
     "start_time": "2022-02-11T04:03:27.739448Z"
    }
   },
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:47:44.890895Z",
     "start_time": "2022-02-11T04:47:44.708818Z"
    }
   },
   "outputs": [],
   "source": [
    "l1_penalty = np.logspace(1, 7, num=13)\n",
    "RSS_val=[]\n",
    "for l1_ in l1_penalty:\n",
    "    model = linear_model.Lasso(alpha=l1_, normalize=True)\n",
    "    X = training[all_features]\n",
    "    y = training['price']\n",
    "    X_val = validation[all_features]\n",
    "    y_val = validation['price']\n",
    "    model.fit(X,y) # learn weights on training set \n",
    "    y_hat_val = model.predict(X_val)\n",
    "    RSS = sum((y_val-y_hat_val)**2)\n",
    "    RSS_val.append(RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUIZ QUESTION: What was the best value for the `l1_penalty`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:50:43.876174Z",
     "start_time": "2022-02-11T04:50:43.866173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1 = l1_penalty[RSS_val.index(np.min(RSS_val))]\n",
    "best_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:50:59.922957Z",
     "start_time": "2022-02-11T04:50:59.822958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.846740e+13\n"
     ]
    }
   ],
   "source": [
    "best_l1 = l1_penalty[RSS_val.index(np.min(RSS_val))]\n",
    "X = training [all_features]\n",
    "X_test = testing [all_features]\n",
    "y = training['price']\n",
    "y_test = testing ['price']\n",
    "# initialize model name & parameters\n",
    "model = linear_model.Lasso(alpha=best_l1, normalize=True)\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "y_hat_test = model.predict(X_test)\n",
    "RSS_test = sum((y_test-y_hat_test)**2)\n",
    "print(\"{:e}\".format(RSS_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUIZ QUESTION: Also, using this value of L1 penalty, how many nonzero weights do you have?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-11T04:51:55.781084Z",
     "start_time": "2022-02-11T04:51:55.764121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T21:39:56.819239Z",
     "start_time": "2022-02-13T21:39:56.804240Z"
    }
   },
   "source": [
    "You are going to implement a simple, two phase procedure to achieve this goal:\n",
    "\n",
    "Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "\n",
    "Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`.\n",
    "\n",
    "10. Assign 7 to the variable `max_nonzeros`.\n",
    "\n",
    "11. Exploring large range of l1_penalty\n",
    "\n",
    "For l1_penalty in np.logspace(1, 4, num=20):\n",
    "\n",
    "Fit a regression model with a given l1_penalty on TRAIN data. Add `alpha=l1_penalty` and `normalize=True` to the parameter list.\n",
    "\n",
    "Extract the weights of the model and count the number of nonzeros. Take account of the intercept as we did in #8, adding 1 whenever the intercept is nonzero. Save the number of nonzeros to a list.\n",
    "\n",
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "12. Out of this large range, we want to find the two ends of our desired narrow range of l1_penalty. At one end, we will have l1_penalty values that have too few non-zeros, and at the other end, we will have an l1_penalty that has too many non-zeros.\n",
    "\n",
    "More formally, find:\n",
    "\n",
    "The largest l1_penalty that has more non-zeros than ‘max_nonzeros’ (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)Store this value in the variable ‘l1_penalty_min’ (we will use it later)\n",
    "\n",
    "The smallest l1_penalty that has fewer non-zeros than ‘max_nonzeros’ (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)Store this value in the variable ‘l1_penalty_max’ (we will use it later)\n",
    "\n",
    "Hint: there are many ways to do this, e.g.:\n",
    "\n",
    "Programmatically within the loop above\n",
    "\n",
    "Creating a list with the number of non-zeros for each value of l1_penalty and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:09:59.524062Z",
     "start_time": "2022-02-13T22:09:58.448001Z"
    }
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7\n",
    "# max_nonzero_id = np.sort((-model.coef_).argsort()[:max_nonzeros])\n",
    "# max_nonzero_features = [all_features[i] for i in max_nonzero_id]\n",
    "l1_penalty_list = np.logspace(1, 4, num=20) \n",
    "number_of_nonzeros= dict()\n",
    "for l1_penalty in l1_penalty_list:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    X = training[all_features]\n",
    "    y = training['price']\n",
    "    model.fit(X,y) # learn weights on training set \n",
    "    number_of_nonzeros [l1_penalty] = np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_min = 183.29807108324357\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:24:57.844801Z",
     "start_time": "2022-02-13T22:24:57.832530Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in number_of_nonzeros.items():\n",
    "    if value > max_nonzeros:\n",
    "        min_l1_penalty = key\n",
    "        continue\n",
    "    if value < max_nonzeros:\n",
    "        max_l1_penalty = key\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What values did you find for l1_penalty_min and l1_penalty_max?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:25:07.061922Z",
     "start_time": "2022-02-13T22:25:07.046776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127.42749857031335, 263.6650898730358)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_l1_penalty,max_l1_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:18:54.274661Z",
     "start_time": "2022-02-13T22:18:54.249270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10.0: 15,\n",
       " 14.38449888287663: 15,\n",
       " 20.6913808111479: 15,\n",
       " 29.76351441631318: 15,\n",
       " 42.81332398719393: 13,\n",
       " 61.58482110660264: 12,\n",
       " 88.58667904100822: 11,\n",
       " 127.42749857031335: 10,\n",
       " 183.29807108324357: 7,\n",
       " 263.6650898730358: 6,\n",
       " 379.26901907322497: 6,\n",
       " 545.5594781168514: 6,\n",
       " 784.7599703514607: 5,\n",
       " 1128.8378916846884: 3,\n",
       " 1623.776739188721: 3,\n",
       " 2335.7214690901214: 2,\n",
       " 3359.818286283781: 1,\n",
       " 4832.930238571752: 1,\n",
       " 6951.927961775606: 1,\n",
       " 10000.0: 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_nonzeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring narrower range of l1_penalty\n",
    "\n",
    "We now explore the region of l1_penalty we found: between ‘l1_penalty_min’ and ‘l1_penalty_max’. We look for the L1 penalty in this range that produces exactly the right number of nonzeros and also minimizes RSS on the VALIDATION set.\n",
    "\n",
    "For l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "\n",
    "Fit a regression model with a given l1_penalty on TRAIN data. As before, use \"alpha=l1_penalty\" and \"normalize=True\".\n",
    "\n",
    "Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity equal to ‘max_nonzeros’. (Again, take account of the intercept when counting the number of nonzeros.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:51:13.291155Z",
     "start_time": "2022-02-13T22:51:12.689345Z"
    }
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(min_l1_penalty,max_l1_penalty,20)\n",
    "RSS_val_narrow = dict()\n",
    "for l1_penalty  in l1_penalty_values:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize=True)\n",
    "    X = training[all_features]\n",
    "    y = training['price']\n",
    "    model.fit(X,y) # learn weights on training set \n",
    "    X_val = validation[all_features]\n",
    "    y_val = validation['price']\n",
    "    y_hat_val = model.predict(X_val)\n",
    "    RSS = sum((y_val-y_hat_val)**2)\n",
    "    RSS_val_narrow [l1_penalty] = [np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_),RSS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Quiz Question: What value of l1_penalty in our narrow range has the lowest RSS on the VALIDATION set and has sparsity equal to ‘max_nonzeros’?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:50:27.258252Z",
     "start_time": "2022-02-13T22:50:27.240908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{127.42749857031335: [10, '4.35375e+14'],\n",
       " 134.5978981125619: [10, '4.37009e+14'],\n",
       " 141.76829765481045: [8, '4.38236e+14'],\n",
       " 148.938697197059: [8, '4.39159e+14'],\n",
       " 156.10909673930755: [7, '4.40037e+14'],\n",
       " 163.2794962815561: [7, '4.40777e+14'],\n",
       " 170.44989582380464: [7, '4.41567e+14'],\n",
       " 177.6202953660532: [7, '4.42406e+14'],\n",
       " 184.79069490830176: [7, '4.43297e+14'],\n",
       " 191.96109445055032: [7, '4.44240e+14'],\n",
       " 199.13149399279888: [7, '4.45231e+14'],\n",
       " 206.3018935350474: [6, '4.46269e+14'],\n",
       " 213.47229307729594: [6, '4.47113e+14'],\n",
       " 220.6426926195445: [6, '4.47998e+14'],\n",
       " 227.81309216179307: [6, '4.48925e+14'],\n",
       " 234.98349170404163: [6, '4.49892e+14'],\n",
       " 242.1538912462902: [6, '4.50901e+14'],\n",
       " 249.32429078853872: [6, '4.51952e+14'],\n",
       " 256.49469033078725: [6, '4.53044e+14'],\n",
       " 263.6650898730358: [6, '4.54177e+14']}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS_val_narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:51:15.021117Z",
     "start_time": "2022-02-13T22:51:15.008880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.10909673930755\n"
     ]
    }
   ],
   "source": [
    "min_RSS = 1e100\n",
    "for key,value in RSS_val_narrow.items():\n",
    "    if value[0]==7 and value[1]<min_RSS:\n",
    "        min_RSS = value[1]\n",
    "        best_l1_penalty = key\n",
    "print(best_l1_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What features in this model have non-zero coefficients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T22:53:10.714249Z",
     "start_time": "2022-02-13T22:53:10.667186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'grade',\n",
       " 'sqft_basement']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_nonzeros = 7\n",
    "model = linear_model.Lasso(alpha=best_l1_penalty, normalize=True)\n",
    "X = training[all_features]\n",
    "y = training['price']\n",
    "model.fit(X,y) # learn weights on training set \n",
    "max_nonzero_id = np.sort((-model.coef_).argsort()[:max_nonzeros])\n",
    "max_nonzero_features = [all_features[i] for i in max_nonzero_id]\n",
    "max_nonzero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
